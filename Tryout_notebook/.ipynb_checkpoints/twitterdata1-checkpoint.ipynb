{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOTEBOOK FOR GATHERING HISTORICAL TWEETS ###\n",
    "import pandas as pd\n",
    "from twitterscraper import query_tweets\n",
    "import datetime as dt\n",
    "import os\n",
    "import pickle as pkl\n",
    "\n",
    "class DBbuilder():\n",
    "    def __init__(self):\n",
    "        self.keywords = ['stocks','oil','forex','gold','commodities','crypto','CFD']\n",
    "        self.help_querry = ' -filter:links' # min_replies:10 trading min_faves:10 \n",
    "        self.begin_date = dt.date(2018,1,1)\n",
    "        self.end_date = dt.date(2019,1,1)\n",
    "        self.date_range = pd.bdate_range(self.begin_date,self.end_date)\n",
    "        self.dt_list = self.date_range.strftime('%Y-%m-%d').tolist()\n",
    "        self.home_folder = '/home/lau/Projects/twitter_data' \n",
    "        self.folder_list = []\n",
    "        self.limit = 10\n",
    "        \n",
    "    def create_folders(self):\n",
    "        # create folder of every keyword of different querries\n",
    "        paths = []\n",
    "        for key_word in self.keywords:\n",
    "            path = self.home_folder + '/' + key_word\n",
    "            try:\n",
    "                os.mkdir(path)\n",
    "                paths.append(path)\n",
    "            except:\n",
    "                print (\"Creation of key directory %s failed\" % path)\n",
    "                \n",
    "        # now in every folder create monthly folders : \n",
    "        for path_ in paths:\n",
    "            for date in self.dt_list:\n",
    "                path = path_ + '/' + date\n",
    "                try:\n",
    "                    os.mkdir(path)\n",
    "                    self.folder_list.append(path)\n",
    "                except:\n",
    "                    print (\"Creation of date directory %s failed\" % path)\n",
    "        \n",
    "    def scrape(self):\n",
    "        dates = list(zip(self.date_range[:-1],self.date_range[1:]))\n",
    "        #dates = list(zip(self.dt_list[:-1],self.dt_list[1:]))\n",
    "        querries = list(map(lambda x: x + self.help_querry,self.keywords))\n",
    "        for i,querry in enumerate(querries):\n",
    "            for j,date in enumerate(dates):\n",
    "                #date_querry = ' since:' + date[0] + ' untill:' + date[1]\n",
    "                tweets = query_tweets(querry,limit = self.limit, begindate = date[0].date(),\n",
    "                                     enddate = date[1].date())\n",
    "                \n",
    "                print(i,j)\n",
    "                print(len(self.dt_list))\n",
    "                fname = self.home_folder+'/'+self.keywords[i]+'/'+self.dt_list[j]+'/'+querry+'.txt'\n",
    "                file = open(fname,'w')\n",
    "                for i,tweet in enumerate(tweets):\n",
    "                    file.write(str(i) + ' ' + tweet.timestamp.strftime('%Y-%m-%d %H:%M:%S ') + tweet.text + '\\n')\n",
    "                file.close()\n",
    "                # also save as pkl : \n",
    "                pkl.dump(tweets,open(fname[:-3]+'.pkl','wb'))\n",
    "        \n",
    "        \n",
    "#             #Or save the retrieved tweets to file:\n",
    "#     file = open(“output.txt”,”w”)\n",
    "#     for tweet in query_tweets(\"Trump OR Clinton\", 10):\n",
    "#         file.write(tweet.encode('utf-8'))\n",
    "#     file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: queries: ['stocks -filter:links since:2018-01-01 until:2018-01-02']\n",
      "INFO: Querying stocks -filter:links since:2018-01-01 until:2018-01-02\n",
      "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=stocks%20-filter%3Alinks%20since%3A2018-01-01%20until%3A2018-01-02&l=\n",
      "INFO: Using proxy 36.66.191.194:42945\n",
      "INFO: Got 17 tweets for stocks%20-filter%3Alinks%20since%3A2018-01-01%20until%3A2018-01-02.\n",
      "INFO: Got 17 tweets (17 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: queries: ['stocks -filter:links since:2018-01-02 until:2018-01-03']\n",
      "INFO: Querying stocks -filter:links since:2018-01-02 until:2018-01-03\n",
      "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=stocks%20-filter%3Alinks%20since%3A2018-01-02%20until%3A2018-01-03&l=\n",
      "INFO: Using proxy 36.66.191.194:42945\n",
      "INFO: Got 17 tweets for stocks%20-filter%3Alinks%20since%3A2018-01-02%20until%3A2018-01-03.\n",
      "INFO: Got 17 tweets (17 new).\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-28f4b08197f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbuilder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDBbuilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#builder.create_folders()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-eead16b266d2>\u001b[0m in \u001b[0;36mscrape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 tweets = query_tweets(querry,limit = self.limit, begindate = date[0].date(),\n\u001b[1;32m     49\u001b[0m                                      enddate = date[1].date())\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhome_folder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mquerry\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "builder = DBbuilder()\n",
    "#builder.create_folders()\n",
    "builder.scrape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### keywords = ['stocks','oil','forex','gold','commodities','crypto','CFD']\n",
    "help_querry = ['trading']\n",
    "print(list(map(lambda x: x + ' AND trading',keywords)))\n",
    "\n",
    "import os\n",
    "from functools import reduce\n",
    "# # define the name of the directory to be created\n",
    "# path = \"/tmp/year\"\n",
    "\n",
    "# try:\n",
    "#     os.mkdir(path)\n",
    "# except OSError:\n",
    "#     print (\"Creation of the directory %s failed\" % path)\n",
    "# else:\n",
    "#     print (\"Successfully created the directory %s \" % path)\n",
    "\n",
    "\n",
    "start = dt.date(2011, 1, 1)\n",
    "\n",
    "end = dt.date(2012, 1, 1)\n",
    "\n",
    "index = pd.bdate_range(start, end)#.strftime('%Y-%m-%d').tolist()\n",
    "print(len(index))\n",
    "print(type(index))\n",
    "print(index)\n",
    "\n",
    "index = list(zip(index[:-1],index[1:]))\n",
    "\n",
    "# dates = list(map(lambda x: [(x[i],x[i+1]) for i in range(len(x)-1)],index))\n",
    "\n",
    "# index.apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "# print(index.strftime('%Y-%m-%d').tolist())\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
